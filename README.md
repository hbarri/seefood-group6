# Seefood Application
### CEG4110 (Software Engineering) Group 6

Our SeeFood Android Application is designed as an entertaining piece of software that enables users to share the experience of Artificial Intelligence. Our mobile implementation of SeeFood will use a simple UI, web services, and a local device environment to unveil the enjoyment of testing the shrewdness of Machine Learning. The basic use of this SeeFood application is to be able to reliably detect if an image is of any kind of food. The application will allow the user to either take multiple images or upload from their phone’s gallery and be able to receive a reasonably-timed response from the AI informing the user if the image(s) contain food or not. This response would also indicate a confidence scale to graphically illustrate the AI’s confidence of its response to the image. Furthermore, this application will allow the user to view past images submitted by all users for analysis by the AI in a gallery format. This application should be functional as well as graphically appealing to the user. This will be accomplished by designing and implementing an Android application that uses an API to interact with the AI that will be hosted on an Amazon Web Services EC2 Virtual Machine. Because the AI and database is hosted on the server, all users will be able to view the same gallery.

The application can be launched on an android device by cloning the project, opening it up in android studio, and launching the application on the device. Below shows screenshots of the application in action.

<img src="https://user-images.githubusercontent.com/22596783/49658039-0f1fdd00-fa0f-11e8-95b9-d19eec7eaab5.jpg" width="300" height="550">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="https://user-images.githubusercontent.com/22596783/49658074-265eca80-fa0f-11e8-9d0e-1a4618efb72b.jpg" width="300" height="550">

Above, you can see the home page of the application. It gives the user the option to capture an image, upload an image, or visit the gallery. It also has a help dialog on the top right corner of the page that gives the user information on the application and how to use it.

Once the user selects/captures an image, the user will be redirected to the second page to confirm their image selection. This is where
they have the option to add more images by selecting either the upload image icon (right icon) or capture image icon (left icon). The user can also remove specific images by selecting the "x" on the top right corner of the image. The user can then select the eye icon in the middle to send their selected images to the AI and get redirected to the application gallery where they will be able to select any 
of the tested images and view the response from the AI.

<img src="https://user-images.githubusercontent.com/22596783/49658227-91a89c80-fa0f-11e8-974f-287c72687fb6.jpg" width="300" height="550">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="https://user-images.githubusercontent.com/22596783/49658302-bbfa5a00-fa0f-11e8-8bcb-1b2bc6881c84.jpg" width="300" height="550">

The gallery also gives the user the capability to like their favorite images by clicking on the image's heart icon. They can then filter based on their favorited images and only be able to see those by clicking on the heart icon on the top right corner of the gallery view (as shown below). Users are also able to delete images from the gallery if they decide they do not want to see an image anymore. This is done by clicking on the edit icon on the top right of the gallery view, selecting the "x" of the images they wish to delete, and clicking done.

<img src="https://user-images.githubusercontent.com/22596783/49658619-75f1c600-fa10-11e8-929e-2361a7e2ce0e.jpg" width="300" height="550">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="https://user-images.githubusercontent.com/22596783/49658655-915cd100-fa10-11e8-8c57-40187155a2c5.jpg" width="300" height="550">

To view the response from the AI, the user would be able to select the image in question. The application will pull up the image itself, the date it was created, if the image contains food or not, if the image is favorited, and how confident the AI is in its reponse. The user is also able to favorite their liked images from this screen, as well, by clicking on the heart. This confidence is represented as a gradient at the bottom of the screen with the width of the gradient based on the percentage. The confidence gradient will turn red if the image is not food and will turn green if the image is food. This percentage was calculated based on a log function given from the two values returned from the AI.

<img src="https://user-images.githubusercontent.com/22596783/49659338-0f6da780-fa12-11e8-87f0-e58550d15db7.jpg" width="300" height="550">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="https://user-images.githubusercontent.com/22596783/49659353-18f70f80-fa12-11e8-8e65-0733a6f623e0.jpg" width="300" height="550">

The user is able to scroll between the images by clicking on the right and left buttons beside the image. Furthermore, the user can also change the image name through clicking on the edit button on the top right, inputting the new image name, and submitting that. The user is also able to inflate the image by clicking on the image itself and saving it to their local gallery through clicking on the save button on the top right.

<img src="https://user-images.githubusercontent.com/22596783/49659639-ab97ae80-fa12-11e8-9dcc-643ce6788367.jpg" width="270" height="500">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="https://user-images.githubusercontent.com/22596783/49659776-fe716600-fa12-11e8-9ec8-04eeb7971ae8.jpg" width="270" height="500">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="https://user-images.githubusercontent.com/22596783/49659659-b3efe980-fa12-11e8-9f5f-82dad54b5451.jpg" width="270" height="500">
